{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bc6f355-8f66-403c-8b72-80ee5dd876aa",
   "metadata": {},
   "source": [
    "### <center>Additional prepreprocessing for NOAA SLR data</center>\n",
    "\n",
    "The National Oceanic and Atmospheric Administration (NOAA) has identified coastal plains with the US that would be impacted at various levels of sea level rise. Processing these files takes several hours for each scenario (1ft, 3ft, 6ft, 7ft and 10ft) given the complexity of the underlying geospatial data (identification and extraction of the geospatial layer for each region, spatial joins on multi polygon shapes). Therefore, the relevant files are pre-processed here and written to disk locally. They can then be read in directly during the analysis stage (Analysis_and_Visulization.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c43f29ac-7cf8-4889-9e0b-e4f0f911a203",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6f50eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_name</th>\n",
       "      <th>state_name</th>\n",
       "      <th>geometry</th>\n",
       "      <th>county_code</th>\n",
       "      <th>census_tract_code</th>\n",
       "      <th>ccounty_flag</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21118</th>\n",
       "      <td>NY</td>\n",
       "      <td>Suffolk</td>\n",
       "      <td>New York</td>\n",
       "      <td>POLYGON ((-72.86509 40.83438, -72.84120 40.829...</td>\n",
       "      <td>36103</td>\n",
       "      <td>36103159411</td>\n",
       "      <td>1</td>\n",
       "      <td>NorthEast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29088</th>\n",
       "      <td>CA</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>California</td>\n",
       "      <td>POLYGON ((-121.93184 37.31695, -121.91500 37.3...</td>\n",
       "      <td>06085</td>\n",
       "      <td>06085502103</td>\n",
       "      <td>1</td>\n",
       "      <td>SouthWest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>POLYGON ((-73.99506 40.72881, -73.99146 40.731...</td>\n",
       "      <td>36061</td>\n",
       "      <td>36061005700</td>\n",
       "      <td>1</td>\n",
       "      <td>NorthEast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      state_code  county_name  state_name  \\\n",
       "21118         NY      Suffolk    New York   \n",
       "29088         CA  Santa Clara  California   \n",
       "2757          NY     New York    New York   \n",
       "\n",
       "                                                geometry county_code  \\\n",
       "21118  POLYGON ((-72.86509 40.83438, -72.84120 40.829...       36103   \n",
       "29088  POLYGON ((-121.93184 37.31695, -121.91500 37.3...       06085   \n",
       "2757   POLYGON ((-73.99506 40.72881, -73.99146 40.731...       36061   \n",
       "\n",
       "      census_tract_code  ccounty_flag     region  \n",
       "21118       36103159411             1  NorthEast  \n",
       "29088       06085502103             1  SouthWest  \n",
       "2757        36061005700             1  NorthEast  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_files():\n",
    "    \"\"\" Reading in the supporting files needed for preprocessing the SLR data\"\"\"\n",
    "    \n",
    "    ccounties = pd.read_pickle(\"Data/Final_Data/cleaned_coastal_counties.pkl\")\n",
    "    gs_df_cc = pd.read_pickle(\"Data/Final_Data/cleaned_coastal_geodf.pkl\")\n",
    "    return ccounties, gs_df_cc\n",
    "\n",
    "ccounties, gs_df_cc = data_files()\n",
    "gs_df_cc.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e286675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##the relevant files have already been unzipped so we should not need to run this\n",
    "def SLR_unzip(folder_path = 'Data/Interim_Data/SLR/raw/'):\n",
    "    \n",
    "    \"\"\" This function unzips all the geospatial files that have been bulk downloaded from the NOAA website. These files \n",
    "        contain the SLR shapefiles for the coastal states/counties in scope for this project\n",
    "    \n",
    "        I/P: Optional parent folder path\n",
    "        O/P: None (Unzipped files are saved directly in the specified folder)\"\"\"\n",
    "\n",
    "    for item in os.listdir(f'{folder_path}'): \n",
    "        archive = zipfile.ZipFile(f'{folder_path}{item}')\n",
    "        for file in archive.namelist():\n",
    "            if file != \"TX_Central_slr_final_dist.gdb\":\n",
    "                if file.endswith('.gdbtable') or file.endswith('.gpkg'): \n",
    "                    archive.extract(file, f'{folder_path[:-4]}/interim/')\n",
    "            else:\n",
    "                archive.extract(file, f'{folder_path[:-4]}/interim/')              \n",
    "    return\n",
    "\n",
    "# SLR_data_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3abb7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##function needed to create the SLR datafame\n",
    "def slr_flagging(gs_df_cc, temp_df, st_cd):\n",
    "    \n",
    "    \"\"\"Given the complexity of the slr shapes (multipolygon) the sjoin runs very slowly when the entire slr gdB and the main \n",
    "    gdB are joined. Therefore, the gdB for each slr file needs to be joined individually. This function performs an inner\n",
    "    sjoin and returns the intersecting census tracts. \n",
    "    \n",
    "    I/P: main geospatial database, slr geospatial database, state code to be used\n",
    "    O/P: indices in the main dB that are found intersecting with the slr dB\"\"\"\n",
    "    \n",
    "    gs_df_st = gs_df_cc[gs_df_cc.state_code == st_cd]\n",
    "    intersecting_census_tracts = temp_df.sjoin(gs_df_st, how ='inner').ud_census_tract_code.unique()\n",
    "\n",
    "    return list(intersecting_census_tracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc5e7250",
   "metadata": {},
   "outputs": [],
   "source": [
    "##function needed to create the SLR datafame\n",
    "def SLR_df(gs_df_cc, slr_ft, folder_path = 'Data/Interim_Data/SLR/interim/'):\n",
    "    \n",
    "    \"\"\"For each SLR shapefile, this function extracts the layer relevant to the sea level rise being considered and \n",
    "    creates the corresponding gdB. This gdB is passed to a sister function slr flagging where a sjoin is performed with\n",
    "    the main gdB and the corresponding intersecting census tracts are returned. Finally, all such intersecting census \n",
    "    tracts are consolidated (slr_df). The slr_df is used to set SLR flags in the main gdB in the analysis \n",
    "    stage (Analysis_and_Visualization.ipynb)\n",
    "    \n",
    "    I/P: main geospatial dB, sea level rise scenario to consider, optional folder path\n",
    "    O/P: dataframe of consolidated interesting census tracts\"\"\"\n",
    "    \n",
    "    slr_ct = []  #master list of intersecting census tracts\n",
    "    for item in os.listdir(f'{folder_path}'):\n",
    "        \n",
    "        if item.endswith(\".gpkg\"):    #metadata here: https://www.fisheries.noaa.gov/inport/item/48106\n",
    "            relevant_layer =  [layer for layer in fiona.listlayers(f'{folder_path}{item}') if f'slr_{slr_ft}_0ft' in layer][0]\n",
    "\n",
    "        else: #for items that are folders\n",
    "            try:\n",
    "                relevant_layer = [layer for layer in fiona.listlayers(f'{folder_path}{item}') if f'slr_{slr_ft}ft' in layer][0]\n",
    "            except: \n",
    "                print(f\"this item failed to create temp_df: {item}\")  #testing (#no layers in the TX_Central_slr_final_dist.gdb)\n",
    "                continue\n",
    "\n",
    "            temp_df = gpd.read_file(f'{folder_path}{item}', layer = relevant_layer)\n",
    "\n",
    "            try:\n",
    "                slr_ct = set(list(slr_ct) + slr_flagging(gs_df_cc, temp_df[[\"geometry\"]], item[:2]))\n",
    "                print(f\"completed for {item} and {relevant_layer}\") #testing\n",
    "            except:\n",
    "                print(f\"FAILED for {item} and {relevant_layer}\") #testing\n",
    "                pass #no data for provided slr level\n",
    "\n",
    "    #consolidate dataframe of interesting census tracts\n",
    "    slr_df = pd.DataFrame({\"slr_census_tracts\": list(slr_ct), f\"slr_{slr_ft}_ft\" : [1] * len(slr_ct)})\n",
    "    slr_df.to_pickle(f'Data/Final_Data/slr_{slr_ft}_censustracts.pkl')\n",
    "    \n",
    "    return slr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9836b9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## slr_1ft_df = SLR_df(gs_df_cc, \"1\") #do not re-run; takes forever. Read in the file instead\n",
    "# slr_1ft_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3f8042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slr_2ft_df = SLR_df(gs_df_cc, \"2\") #do not re-run; takes forever. Read in the file instead\n",
    "# slr_2ft_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "315f30a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slr_3ft_df = SLR_df(gs_df_cc, \"3\") #do not re-run; takes forever. Read in the file instead\n",
    "# slr_3ft_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af2a7d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slr_4ft_df = SLR_df(gs_df_cc, \"4\") #do not re-run; takes forever. Read in the file instead\n",
    "# slr_4ft_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4708820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slr_5ft_df = SLR_df(gs_df_cc, \"5\") #do not re-run; takes forever. Read in the file instead\n",
    "# slr_5ft_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb95d605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slr_6ft_df = SLR_df(gs_df_cc, \"6\")  #do not re-run; takes forever. Read in the file instead\n",
    "# slr_6ft_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8601d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slr_7ft_df = SLR_df(gs_df_cc, \"7\") #do not re-run; takes forever. Read in the file instead\n",
    "# slr_7ft_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d557485",
   "metadata": {},
   "outputs": [],
   "source": [
    "## slr_10ft_df = SLR_df(gs_df_cc, \"10\")  #do not re-run; takes forever. Read in the file instead\n",
    "# slr_10ft_df.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
